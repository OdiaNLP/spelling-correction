{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "from collections import Counter\n",
    "from typing import List, Union\n",
    "\n",
    "from gensim.models import FastText\n",
    "from indicnlp.tokenize.indic_tokenize import trivial_tokenize_indic\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# set up the logging to monitor gensim\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s - %(asctime)s: %(message)s\",\n",
    "    datefmt='%H:%M:%S',\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utilities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def tokenize_text(text: List[str]) -> List[List[str]]:\n",
    "    \"\"\"Tokenize text\"\"\"\n",
    "    return [trivial_tokenize_indic(sent) for sent in tqdm(text, desc='tokenize', unit=' sentences')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def train_fasttext(tokenized_text: List[List[str]], size: int = 100, window: int = 5, min_count: int = 1,\n",
    "                   epochs: int = 10,\n",
    "                   random_seed: int = 123, vec_file_path: Union[str, None] = None, ):\n",
    "    \"Learn fasttext embeddings\"\n",
    "    # count the number of cores\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    # create fasttext model\n",
    "    model = FastText(\n",
    "        size=size,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "        workers=cores - 1,\n",
    "        seed=random_seed,\n",
    "    )\n",
    "    # build vocab\n",
    "    model.build_vocab(sentences=tokenized_text, progress_per=1000000)  # show progress after processing every 1M words\n",
    "    # train\n",
    "    model.train(sentences=tokenized_text, total_examples=model.corpus_count, epochs=epochs,\n",
    "                report_delay=10)  # show progress after every 10 seconds\n",
    "    if vec_file_path is not None:\n",
    "        model.wv.save_word2vec_format(vec_file_path, binary=False)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data\n",
    "For learning the Odia word embeddings, we need monolingual Odia text data. You can possibly scrape data from an online source such as Wikipedia. For our experiments now, let's take the Odia monolingual text data available as part of the Indic NLP corpus."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "filename = os.path.join('data/or')\n",
    "assert os.path.isfile(filename)  # sanity check"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "read lines from file: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3594672/3594672 [00:02<00:00, 1568395.63it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    lines = [s.strip() for s in tqdm(f.readlines(), desc='read lines from file')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenize: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3594672/3594672 [01:24<00:00, 42326.60 sentences/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "tokens = tokenize_text(lines)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute frequencies of tokens: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3594672/3594672 [00:20<00:00, 173846.92 sentences/s]\n"
     ]
    }
   ],
   "source": [
    "num_running_toks, num_unique_toks = 0, 0\n",
    "counter = Counter()\n",
    "for toks in tqdm(tokens, desc='compute frequencies of tokens', unit=' sentences'):\n",
    "    counter.update(toks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 3,594,672\n",
      "Number of unique words or equivalantly, the size of vocabulary: 778,862\n",
      "Number of running words: 51,151,273\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of sentences: {len(lines):,}')\n",
    "print(f'Number of unique words or equivalantly, the size of vocabulary: {len(counter):,}')\n",
    "print(f'Number of running words: {sum([freq for _, freq in counter.items()]):,}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "[('à¥¤', 3393061),\n (',', 1191253),\n ('à¬“', 534792),\n ('à¬à¬¹à¬¿', 437185),\n ('à¬ªà¬¾à¬‡à¬', 373726),\n ('à¬¸à­‡', 240775),\n ('à¬¬à­‹à¬²à¬¿', 239837),\n ('à¬ªà¬°à­‡', 224959),\n ('à¬•à¬°à¬¿', 221628),\n ('à¬à¬•', 213516),\n ('à¬®à¬§à­à­Ÿ', 210907),\n ('à¬à¬¬à¬‚', 198988),\n ('à¬•à¬°à¬¿à¬¥à¬¿à¬²à­‡', 195168),\n ('à¬¸à¬¹', 177040),\n ('-', 174796),\n ('à¬–à¬¬à¬°', 169373),\n ('.', 166728),\n ('à¬•à¬°à¬¿à¬¬à¬¾', 166276),\n ('à¬¨à­‡à¬‡', 161728),\n ('à¬¬à­‡à¬³à­‡', 156327)]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# most common words\n",
    "counter.most_common(n=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learn embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:05:54: resetting layer weights\n",
      "INFO - 21:06:07: collecting all words and their counts\n",
      "INFO - 21:06:07: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 21:06:12: PROGRESS: at sentence #1000000, processed 14406915 words, keeping 356423 word types\n",
      "INFO - 21:06:16: PROGRESS: at sentence #2000000, processed 28227997 words, keeping 518060 word types\n",
      "INFO - 21:06:21: PROGRESS: at sentence #3000000, processed 42532970 words, keeping 692676 word types\n",
      "INFO - 21:06:23: collected 778862 word types from a corpus of 51151273 raw words and 3594672 sentences\n",
      "INFO - 21:06:23: Loading a fresh vocabulary\n",
      "INFO - 21:06:25: effective_min_count=20 retains 72827 unique words (9% of original 778862, drops 706035)\n",
      "INFO - 21:06:25: effective_min_count=20 leaves 49262024 word corpus (96% of original 51151273, drops 1889249)\n",
      "INFO - 21:06:26: deleting the raw counts dictionary of 778862 items\n",
      "INFO - 21:06:26: sample=0.001 downsamples 22 most-common words\n",
      "INFO - 21:06:26: downsampling leaves estimated 43948889 word corpus (89.2% of prior 49262024)\n",
      "INFO - 21:06:27: estimated required memory for 72827 words, 333945 buckets and 100 dimensions: 245357740 bytes\n",
      "INFO - 21:06:27: resetting layer weights\n",
      "INFO - 21:06:48: training model with 3 workers on 72827 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 21:06:49: EPOCH 1 - PROGRESS: at 0.55% examples, 243416 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:06:59: EPOCH 1 - PROGRESS: at 6.20% examples, 263122 words/s, in_qsize 6, out_qsize 1\n",
      "INFO - 21:07:09: EPOCH 1 - PROGRESS: at 12.81% examples, 275890 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:07:19: EPOCH 1 - PROGRESS: at 19.56% examples, 282292 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:07:29: EPOCH 1 - PROGRESS: at 26.28% examples, 285299 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:07:39: EPOCH 1 - PROGRESS: at 32.93% examples, 286649 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:07:49: EPOCH 1 - PROGRESS: at 39.70% examples, 288172 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:07:59: EPOCH 1 - PROGRESS: at 46.48% examples, 289260 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:08:09: EPOCH 1 - PROGRESS: at 53.59% examples, 290050 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:08:19: EPOCH 1 - PROGRESS: at 61.48% examples, 291308 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:08:29: EPOCH 1 - PROGRESS: at 69.32% examples, 292218 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:08:39: EPOCH 1 - PROGRESS: at 75.96% examples, 292321 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:08:50: EPOCH 1 - PROGRESS: at 81.09% examples, 291619 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:09:00: EPOCH 1 - PROGRESS: at 87.12% examples, 291221 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:09:10: EPOCH 1 - PROGRESS: at 93.44% examples, 291219 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:09:19: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:09:19: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:09:19: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:09:19: EPOCH - 1 : training on 51151273 raw words (43950159 effective words) took 150.9s, 291321 effective words/s\n",
      "INFO - 21:09:20: EPOCH 2 - PROGRESS: at 0.60% examples, 273460 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:09:30: EPOCH 2 - PROGRESS: at 6.40% examples, 272992 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:09:40: EPOCH 2 - PROGRESS: at 12.33% examples, 266548 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:09:50: EPOCH 2 - PROGRESS: at 18.93% examples, 273662 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:10:00: EPOCH 2 - PROGRESS: at 25.26% examples, 274716 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:10:10: EPOCH 2 - PROGRESS: at 31.84% examples, 277459 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:10:20: EPOCH 2 - PROGRESS: at 38.45% examples, 279467 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:10:30: EPOCH 2 - PROGRESS: at 45.10% examples, 280953 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:10:40: EPOCH 2 - PROGRESS: at 51.84% examples, 282012 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:10:50: EPOCH 2 - PROGRESS: at 59.64% examples, 283726 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:11:00: EPOCH 2 - PROGRESS: at 67.41% examples, 285040 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:11:10: EPOCH 2 - PROGRESS: at 74.66% examples, 285797 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:11:20: EPOCH 2 - PROGRESS: at 79.76% examples, 285395 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:11:30: EPOCH 2 - PROGRESS: at 85.48% examples, 285100 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:11:40: EPOCH 2 - PROGRESS: at 91.51% examples, 285157 words/s, in_qsize 5, out_qsize 1\n",
      "INFO - 21:11:50: EPOCH 2 - PROGRESS: at 98.11% examples, 285216 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:11:53: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:11:53: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:11:53: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:11:53: EPOCH - 2 : training on 51151273 raw words (43950019 effective words) took 154.0s, 285352 effective words/s\n",
      "INFO - 21:11:54: EPOCH 3 - PROGRESS: at 0.60% examples, 268554 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:12:04: EPOCH 3 - PROGRESS: at 6.67% examples, 283431 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:12:14: EPOCH 3 - PROGRESS: at 13.46% examples, 289914 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:12:24: EPOCH 3 - PROGRESS: at 20.20% examples, 291618 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:12:34: EPOCH 3 - PROGRESS: at 26.92% examples, 292877 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:12:44: EPOCH 3 - PROGRESS: at 33.63% examples, 293350 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:12:54: EPOCH 3 - PROGRESS: at 40.37% examples, 293654 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:13:04: EPOCH 3 - PROGRESS: at 47.16% examples, 294132 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:13:14: EPOCH 3 - PROGRESS: at 54.45% examples, 294655 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:13:24: EPOCH 3 - PROGRESS: at 62.31% examples, 295423 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:13:34: EPOCH 3 - PROGRESS: at 70.18% examples, 296045 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:13:44: EPOCH 3 - PROGRESS: at 76.52% examples, 295497 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:13:54: EPOCH 3 - PROGRESS: at 81.64% examples, 294534 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:14:04: EPOCH 3 - PROGRESS: at 87.68% examples, 293630 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:14:14: EPOCH 3 - PROGRESS: at 93.99% examples, 293175 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:14:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:14:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:14:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:14:23: EPOCH - 3 : training on 51151273 raw words (43949266 effective words) took 150.1s, 292755 effective words/s\n",
      "INFO - 21:14:24: EPOCH 4 - PROGRESS: at 0.59% examples, 259355 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:14:34: EPOCH 4 - PROGRESS: at 6.48% examples, 274866 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:14:44: EPOCH 4 - PROGRESS: at 13.24% examples, 284930 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:14:54: EPOCH 4 - PROGRESS: at 19.94% examples, 287834 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:15:04: EPOCH 4 - PROGRESS: at 26.68% examples, 290253 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:15:14: EPOCH 4 - PROGRESS: at 33.48% examples, 291958 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:15:24: EPOCH 4 - PROGRESS: at 40.33% examples, 293314 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:15:34: EPOCH 4 - PROGRESS: at 47.18% examples, 294088 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:15:44: EPOCH 4 - PROGRESS: at 54.56% examples, 294910 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:15:54: EPOCH 4 - PROGRESS: at 62.44% examples, 295707 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:16:04: EPOCH 4 - PROGRESS: at 70.38% examples, 296627 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:16:14: EPOCH 4 - PROGRESS: at 76.68% examples, 296239 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:16:24: EPOCH 4 - PROGRESS: at 81.80% examples, 295273 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:16:34: EPOCH 4 - PROGRESS: at 88.09% examples, 295133 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:16:44: EPOCH 4 - PROGRESS: at 94.67% examples, 295121 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:16:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:16:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:16:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:16:52: EPOCH - 4 : training on 51151273 raw words (43946253 effective words) took 148.8s, 295278 effective words/s\n",
      "INFO - 21:16:53: EPOCH 5 - PROGRESS: at 0.64% examples, 275717 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:17:03: EPOCH 5 - PROGRESS: at 6.83% examples, 288999 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:17:13: EPOCH 5 - PROGRESS: at 13.68% examples, 294461 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:17:23: EPOCH 5 - PROGRESS: at 20.51% examples, 296258 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:17:33: EPOCH 5 - PROGRESS: at 27.34% examples, 297674 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:17:43: EPOCH 5 - PROGRESS: at 34.13% examples, 297909 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:17:53: EPOCH 5 - PROGRESS: at 40.99% examples, 298302 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:18:03: EPOCH 5 - PROGRESS: at 47.85% examples, 298607 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:18:13: EPOCH 5 - PROGRESS: at 55.36% examples, 299208 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:18:23: EPOCH 5 - PROGRESS: at 63.33% examples, 299922 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:18:33: EPOCH 5 - PROGRESS: at 71.30% examples, 300503 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:18:43: EPOCH 5 - PROGRESS: at 77.35% examples, 299877 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:18:53: EPOCH 5 - PROGRESS: at 82.48% examples, 298584 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:19:03: EPOCH 5 - PROGRESS: at 88.73% examples, 298262 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:19:13: EPOCH 5 - PROGRESS: at 95.52% examples, 298130 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:19:19: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:19:19: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:19:19: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:19:19: EPOCH - 5 : training on 51151273 raw words (43950372 effective words) took 147.4s, 298186 effective words/s\n",
      "INFO - 21:19:20: EPOCH 6 - PROGRESS: at 0.62% examples, 280891 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:19:30: EPOCH 6 - PROGRESS: at 6.71% examples, 284589 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:19:40: EPOCH 6 - PROGRESS: at 13.42% examples, 289009 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:19:50: EPOCH 6 - PROGRESS: at 20.62% examples, 297600 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:20:00: EPOCH 6 - PROGRESS: at 27.80% examples, 302096 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:20:10: EPOCH 6 - PROGRESS: at 34.98% examples, 304806 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:20:20: EPOCH 6 - PROGRESS: at 42.18% examples, 306612 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 21:20:30: EPOCH 6 - PROGRESS: at 49.45% examples, 308116 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:20:41: EPOCH 6 - PROGRESS: at 57.65% examples, 309761 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:20:51: EPOCH 6 - PROGRESS: at 66.05% examples, 311051 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:21:01: EPOCH 6 - PROGRESS: at 74.20% examples, 311945 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:21:11: EPOCH 6 - PROGRESS: at 79.70% examples, 311188 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:21:21: EPOCH 6 - PROGRESS: at 85.94% examples, 310888 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:21:31: EPOCH 6 - PROGRESS: at 92.53% examples, 310728 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:21:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:21:41: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:21:41: EPOCH 6 - PROGRESS: at 100.00% examples, 311019 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 21:21:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:21:41: EPOCH - 6 : training on 51151273 raw words (43947395 effective words) took 141.3s, 311016 effective words/s\n",
      "INFO - 21:21:42: EPOCH 7 - PROGRESS: at 0.66% examples, 296846 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:21:52: EPOCH 7 - PROGRESS: at 7.09% examples, 300191 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:22:02: EPOCH 7 - PROGRESS: at 14.25% examples, 306503 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:22:12: EPOCH 7 - PROGRESS: at 21.39% examples, 308917 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:22:22: EPOCH 7 - PROGRESS: at 28.49% examples, 310099 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:22:32: EPOCH 7 - PROGRESS: at 35.65% examples, 310922 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:22:42: EPOCH 7 - PROGRESS: at 42.86% examples, 311497 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:22:52: EPOCH 7 - PROGRESS: at 50.05% examples, 311878 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:23:02: EPOCH 7 - PROGRESS: at 58.26% examples, 312585 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:23:12: EPOCH 7 - PROGRESS: at 66.56% examples, 313173 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:23:22: EPOCH 7 - PROGRESS: at 74.52% examples, 313635 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:23:32: EPOCH 7 - PROGRESS: at 79.93% examples, 312334 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:23:42: EPOCH 7 - PROGRESS: at 86.15% examples, 311677 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:23:52: EPOCH 7 - PROGRESS: at 92.74% examples, 311318 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:24:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:24:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:24:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:24:02: EPOCH - 7 : training on 51151273 raw words (43948727 effective words) took 141.2s, 311326 effective words/s\n",
      "INFO - 21:24:03: EPOCH 8 - PROGRESS: at 0.66% examples, 295599 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:24:13: EPOCH 8 - PROGRESS: at 7.13% examples, 301524 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:24:23: EPOCH 8 - PROGRESS: at 14.31% examples, 307608 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:24:33: EPOCH 8 - PROGRESS: at 21.04% examples, 303748 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:24:43: EPOCH 8 - PROGRESS: at 28.16% examples, 306448 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:24:53: EPOCH 8 - PROGRESS: at 35.25% examples, 307232 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:25:03: EPOCH 8 - PROGRESS: at 42.36% examples, 307912 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:25:13: EPOCH 8 - PROGRESS: at 49.45% examples, 308043 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:25:23: EPOCH 8 - PROGRESS: at 57.59% examples, 309411 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:25:33: EPOCH 8 - PROGRESS: at 65.90% examples, 310425 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:25:43: EPOCH 8 - PROGRESS: at 74.07% examples, 311159 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:25:53: EPOCH 8 - PROGRESS: at 79.52% examples, 310254 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:26:03: EPOCH 8 - PROGRESS: at 85.67% examples, 309754 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:26:13: EPOCH 8 - PROGRESS: at 92.20% examples, 309458 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:26:23: EPOCH 8 - PROGRESS: at 99.54% examples, 309531 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:26:24: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:26:24: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:26:24: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:26:24: EPOCH - 8 : training on 51151273 raw words (43949150 effective words) took 142.0s, 309585 effective words/s\n",
      "INFO - 21:26:25: EPOCH 9 - PROGRESS: at 0.66% examples, 291160 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:26:35: EPOCH 9 - PROGRESS: at 7.09% examples, 299512 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:26:45: EPOCH 9 - PROGRESS: at 14.21% examples, 305621 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:26:55: EPOCH 9 - PROGRESS: at 21.35% examples, 308077 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:27:05: EPOCH 9 - PROGRESS: at 28.42% examples, 309172 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:27:15: EPOCH 9 - PROGRESS: at 35.57% examples, 310024 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:27:25: EPOCH 9 - PROGRESS: at 42.72% examples, 310250 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:27:35: EPOCH 9 - PROGRESS: at 49.89% examples, 310756 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:27:45: EPOCH 9 - PROGRESS: at 58.10% examples, 311730 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:27:55: EPOCH 9 - PROGRESS: at 66.41% examples, 312374 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:28:05: EPOCH 9 - PROGRESS: at 74.25% examples, 311932 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:28:15: EPOCH 9 - PROGRESS: at 79.63% examples, 310657 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:28:25: EPOCH 9 - PROGRESS: at 85.73% examples, 309842 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:28:35: EPOCH 9 - PROGRESS: at 92.18% examples, 309376 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:28:45: EPOCH 9 - PROGRESS: at 99.45% examples, 309340 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:28:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:28:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:28:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:28:46: EPOCH - 9 : training on 51151273 raw words (43947799 effective words) took 142.1s, 309355 effective words/s\n",
      "INFO - 21:28:47: EPOCH 10 - PROGRESS: at 0.64% examples, 289632 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:28:57: EPOCH 10 - PROGRESS: at 6.98% examples, 295993 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:29:07: EPOCH 10 - PROGRESS: at 14.09% examples, 303426 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:29:17: EPOCH 10 - PROGRESS: at 21.19% examples, 306383 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:29:27: EPOCH 10 - PROGRESS: at 28.18% examples, 307033 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:29:37: EPOCH 10 - PROGRESS: at 35.27% examples, 307951 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:29:47: EPOCH 10 - PROGRESS: at 42.40% examples, 308495 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:29:57: EPOCH 10 - PROGRESS: at 49.56% examples, 309102 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:30:07: EPOCH 10 - PROGRESS: at 57.65% examples, 310007 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:30:17: EPOCH 10 - PROGRESS: at 65.94% examples, 310778 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:30:27: EPOCH 10 - PROGRESS: at 74.04% examples, 311287 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:30:37: EPOCH 10 - PROGRESS: at 79.45% examples, 310170 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:30:47: EPOCH 10 - PROGRESS: at 85.55% examples, 309585 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:30:57: EPOCH 10 - PROGRESS: at 92.00% examples, 309194 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 21:31:07: EPOCH 10 - PROGRESS: at 99.27% examples, 309242 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:31:08: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:31:08: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:31:08: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:31:08: EPOCH - 10 : training on 51151273 raw words (43949326 effective words) took 142.1s, 309239 effective words/s\n",
      "INFO - 21:31:08: training on a 511512730 raw words (439488466 effective words) took 1460.0s, 301024 effective words/s\n",
      "INFO - 21:31:12: storing 72827x100 projection weights into embeddings.txt\n"
     ]
    }
   ],
   "source": [
    "fasttext_model = train_fasttext(tokenized_text=tokens, size=100, window=5, min_count=20, epochs=10, random_seed=123,\n",
    "                                vec_file_path=os.path.join('embeddings.txt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate embeddings\n",
    "Here we evaluate the embeddings learned by just ðŸ‘€ at the neighbours of a few words and examining if they are similar.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "[('à¬—à¬›à¬¡à¬¾à¬³', 0.8625774383544922),\n ('à¬¬à¬°à¬—à¬›', 0.8207435607910156),\n ('à¬—à¬›à¬°', 0.812586784362793),\n ('à¬—à¬›à¬Ÿà¬¿', 0.7994915246963501),\n ('à¬†à¬®à­à¬¬à¬—à¬›', 0.7820898294448853),\n ('à¬«à­à¬²à¬—à¬›', 0.750383734703064),\n ('à¬•à¬¦à¬³à­€à¬—à¬›', 0.7475508451461792),\n ('à¬¶à¬¾à¬³à¬—à¬›', 0.7465659379959106),\n ('à¬—à¬›à¬Ÿà¬¿à¬', 0.7456701993942261),\n ('à¬¬à¬¾à¬‰à¬à¬¶', 0.7355741262435913)]"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## find words similar to a given word\n",
    "fasttext_model.wv.most_similar('à¬—à¬›', topn=10)  # TODO: misspell it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "[('à¬¸à¬‚à¬—à­€à¬¤', 0.9623903036117554),\n ('à¬¸à¬‚à¬™à­à¬—à­€à¬¤', 0.9553436040878296),\n ('à¬¸à¬™à­à¬—à­€à¬¤à¬°', 0.9166804552078247),\n ('à¬¸à¬™à­à¬—à­€à¬¤à¬•à¬¾à¬°', 0.8910577893257141),\n ('à¬¸à¬‚à¬—à­€à¬¤à¬°', 0.8831936120986938),\n ('à¬¸à¬‚à¬—à­€à¬¤à¬•à¬¾à¬°', 0.8764158487319946),\n ('à¬¸à¬™à­à¬—à­€à¬¤à¬œà­à¬ž', 0.8699268102645874),\n ('à¬—à­€à¬¤à¬¿à¬¨à¬¾à¬Ÿà­à­Ÿ', 0.8680843710899353),\n ('à¬¨à­ƒà¬¤à­à­Ÿà¬—à­€à¬¤', 0.8561346530914307),\n ('à¬¨à¬¾à¬Ÿà­à­Ÿ', 0.8338338136672974)]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('à¬¸à¬™à­à¬—à­€à¬¤', topn=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "[('à¬šà¬³à¬šà¬¿à¬¤à­à¬°', 0.9308711290359497),\n ('à¬šà¬³à¬šà­à¬šà¬¿à¬¤à­à¬°à¬Ÿà¬¿', 0.9191179275512695),\n ('à¬šà¬³à¬šà­à¬šà¬¿à¬¤à­à¬°à¬Ÿà¬¿à¬°', 0.9073216915130615),\n ('à¬šà¬³à¬šà­à¬šà¬¿à¬¤à­à¬°à¬°', 0.8922181129455566),\n ('à¬¸à¬¿à¬¨à­‡à¬®à¬¾', 0.840882420539856),\n ('à¬¸à¬¿à¬¨à­‡à¬®à¬¾à¬Ÿà­‹à¬—à­à¬°à¬¾à¬«à¬°', 0.8325262069702148),\n ('à¬šà¬³à¬šà­à¬šà¬¿à¬¤à­à¬°à¬°à­‡', 0.8220148682594299),\n ('à¬šà¬³à¬šà­à¬šà¬¿à¬¤à­à¬°à¬Ÿà¬¿à¬°à­‡', 0.8215944766998291),\n ('à¬«à¬¿à¬²à­à¬®', 0.8206902742385864),\n ('à¬¸à¬¿à¬¨à­‡', 0.8191198110580444)]"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('à¬šà¬³à¬šà­à¬šà¬¿à¬¤à­à¬°', topn=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Try some misspelled words**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "[('à¬šà¬³à¬šà­à¬šà¬¿à¬¤à­à¬°', 0.8137073516845703),\n ('à¬šà¬³à¬šà­à¬šà¬¿à¬¤à­à¬°à¬Ÿà¬¿à¬°', 0.7877084612846375),\n ('à¬šà¬³à¬šà­à¬šà¬¿à¬¤à­à¬°à¬Ÿà¬¿', 0.7712979316711426),\n ('à¬¸à¬®à­à¬šà­à¬šà¬¿à¬¤', 0.7514731884002686),\n ('à¬šà¬³à¬šà­à¬šà¬¿à¬¤à­à¬°à¬°', 0.7456707954406738),\n ('à¬šà¬³à¬šà­à¬šà¬¿à¬¤à­à¬°à¬Ÿà¬¿à¬°à­‡', 0.7123273611068726),\n ('à¬¸à¬¿à¬¨à­‡', 0.7101430892944336),\n ('à¬¸à¬¿à¬¨à­‡à¬®à¬¾à¬Ÿà­‹à¬—à­à¬°à¬¾à¬«à¬°', 0.709763765335083),\n ('à¬²à­‹à¬•à¬ªà­à¬°à¬¿à­Ÿ', 0.7081252336502075),\n ('à¬«à¬¿à¬²à­à¬®', 0.7038418650627136)]"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('à¬šà¬³à¬šà­à¬šà¬¿à¬¤', topn=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "[('à¬—à­€à¬¤', 0.9316926002502441),\n ('à¬¸à¬‚à¬™à­à¬—à­€à¬¤', 0.891626238822937),\n ('à¬¨à¬¾à¬šà¬—à­€à¬¤', 0.8895268440246582),\n ('à¬¨à­ƒà¬¤à­à­Ÿà¬—à­€à¬¤', 0.8842304944992065),\n ('à¬¸à¬‚à¬—à­€à¬¤', 0.883371114730835),\n ('à¬¸à¬™à­à¬—à­€à¬¤', 0.8755859136581421),\n ('à¬—à­€à¬¤à­', 0.8577066659927368),\n ('à¬—à­€à¬¤à¬¿à¬¨à¬¾à¬Ÿà­à­Ÿ', 0.8234955072402954),\n ('à¬¸à¬‚à¬—à­€à¬¤à¬°', 0.8086755871772766),\n ('à¬¸à¬™à­à¬—à­€à¬¤à¬°', 0.8027265071868896)]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('à¬¸à¬—à­€à¬¤', topn=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}