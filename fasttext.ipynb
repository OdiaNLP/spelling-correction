{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "from collections import Counter\n",
    "from typing import List, Union\n",
    "\n",
    "from gensim.models import FastText\n",
    "from indicnlp.tokenize.indic_tokenize import trivial_tokenize_indic\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# set up the logging to monitor gensim\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s - %(asctime)s: %(message)s\",\n",
    "    datefmt='%H:%M:%S',\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utilities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def tokenize_text(text: List[str]) -> List[List[str]]:\n",
    "    \"\"\"Tokenize text\"\"\"\n",
    "    return [trivial_tokenize_indic(sent) for sent in tqdm(text, desc='tokenize', unit=' sentences')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def train_fasttext(tokenized_text: List[List[str]], size: int = 100, window: int = 5, min_count: int = 1,\n",
    "                   epochs: int = 10,\n",
    "                   random_seed: int = 123, vec_file_path: Union[str, None] = None, ):\n",
    "    \"\"\"Learn fasttext embeddings\"\"\"\n",
    "    # count the number of cores\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    # create fasttext model\n",
    "    model = FastText(\n",
    "        size=size,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "        workers=cores - 1,\n",
    "        seed=random_seed,\n",
    "    )\n",
    "    # build vocab\n",
    "    model.build_vocab(sentences=tokenized_text, progress_per=1000000)  # show progress after processing every 1M words\n",
    "    # train\n",
    "    model.train(sentences=tokenized_text, total_examples=model.corpus_count, epochs=epochs,\n",
    "                report_delay=10)  # show progress after every 10 seconds\n",
    "    if vec_file_path is not None:\n",
    "        model.save(vec_file_path, binary=False)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data\n",
    "For learning the Odia word embeddings, we need monolingual Odia text data. You can possibly scrape data from an online source such as Wikipedia. For our experiments now, let's take the Odia monolingual text data available as part of the Indic NLP corpus."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "filename = os.path.join('data/or')\n",
    "assert os.path.isfile(filename)  # sanity check"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "read lines from file: 100%|██████████| 3594672/3594672 [00:01<00:00, 1887993.40it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    lines = [s.strip() for s in tqdm(f.readlines(), desc='read lines from file')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenize: 100%|██████████| 3594672/3594672 [01:18<00:00, 45640.83 sentences/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "tokens = tokenize_text(lines)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute frequencies of tokens: 100%|██████████| 3594672/3594672 [00:20<00:00, 171988.99 sentences/s]\n"
     ]
    }
   ],
   "source": [
    "num_running_toks, num_unique_toks = 0, 0\n",
    "counter = Counter()\n",
    "for toks in tqdm(tokens, desc='compute frequencies of tokens', unit=' sentences'):\n",
    "    counter.update(toks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 3,594,672\n",
      "Number of unique words or equivalantly, the size of vocabulary: 778,862\n",
      "Number of running words: 51,151,273\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of sentences: {len(lines):,}')\n",
    "print(f'Number of unique words or equivalantly, the size of vocabulary: {len(counter):,}')\n",
    "print(f'Number of running words: {sum([freq for _, freq in counter.items()]):,}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[('।', 3393061),\n (',', 1191253),\n ('ଓ', 534792),\n ('ଏହି', 437185),\n ('ପାଇଁ', 373726),\n ('ସେ', 240775),\n ('ବୋଲି', 239837),\n ('ପରେ', 224959),\n ('କରି', 221628),\n ('ଏକ', 213516),\n ('ମଧ୍ୟ', 210907),\n ('ଏବଂ', 198988),\n ('କରିଥିଲେ', 195168),\n ('ସହ', 177040),\n ('-', 174796),\n ('ଖବର', 169373),\n ('.', 166728),\n ('କରିବା', 166276),\n ('ନେଇ', 161728),\n ('ବେଳେ', 156327)]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# most common words\n",
    "counter.most_common(n=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learn embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:23:09: resetting layer weights\n",
      "INFO - 00:23:19: collecting all words and their counts\n",
      "INFO - 00:23:19: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 00:23:24: PROGRESS: at sentence #1000000, processed 14406915 words, keeping 356423 word types\n",
      "INFO - 00:23:30: PROGRESS: at sentence #2000000, processed 28227997 words, keeping 518060 word types\n",
      "INFO - 00:23:34: PROGRESS: at sentence #3000000, processed 42532970 words, keeping 692676 word types\n",
      "INFO - 00:23:37: collected 778862 word types from a corpus of 51151273 raw words and 3594672 sentences\n",
      "INFO - 00:23:37: Loading a fresh vocabulary\n",
      "INFO - 00:23:37: effective_min_count=20 retains 72827 unique words (9% of original 778862, drops 706035)\n",
      "INFO - 00:23:37: effective_min_count=20 leaves 49262024 word corpus (96% of original 51151273, drops 1889249)\n",
      "INFO - 00:23:38: deleting the raw counts dictionary of 778862 items\n",
      "INFO - 00:23:38: sample=0.001 downsamples 22 most-common words\n",
      "INFO - 00:23:38: downsampling leaves estimated 43948889 word corpus (89.2% of prior 49262024)\n",
      "INFO - 00:23:39: estimated required memory for 72827 words, 333945 buckets and 100 dimensions: 245357740 bytes\n",
      "INFO - 00:23:39: resetting layer weights\n",
      "INFO - 00:23:58: training model with 3 workers on 72827 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 00:23:59: EPOCH 1 - PROGRESS: at 0.32% examples, 121060 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:24:09: EPOCH 1 - PROGRESS: at 3.63% examples, 154516 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:24:19: EPOCH 1 - PROGRESS: at 7.28% examples, 160369 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:24:29: EPOCH 1 - PROGRESS: at 11.18% examples, 163687 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:24:39: EPOCH 1 - PROGRESS: at 14.61% examples, 160187 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:24:50: EPOCH 1 - PROGRESS: at 17.91% examples, 156796 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 00:25:00: EPOCH 1 - PROGRESS: at 21.60% examples, 157738 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:25:10: EPOCH 1 - PROGRESS: at 25.46% examples, 159418 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:25:20: EPOCH 1 - PROGRESS: at 29.33% examples, 160938 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:25:30: EPOCH 1 - PROGRESS: at 33.24% examples, 162145 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:25:40: EPOCH 1 - PROGRESS: at 37.19% examples, 163099 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:25:50: EPOCH 1 - PROGRESS: at 40.89% examples, 162946 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:26:00: EPOCH 1 - PROGRESS: at 44.80% examples, 163589 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:26:10: EPOCH 1 - PROGRESS: at 48.72% examples, 164207 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:26:20: EPOCH 1 - PROGRESS: at 52.99% examples, 164905 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:26:30: EPOCH 1 - PROGRESS: at 57.57% examples, 165563 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:26:40: EPOCH 1 - PROGRESS: at 62.17% examples, 166185 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:26:50: EPOCH 1 - PROGRESS: at 66.76% examples, 166784 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:27:00: EPOCH 1 - PROGRESS: at 70.94% examples, 166365 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:27:10: EPOCH 1 - PROGRESS: at 74.86% examples, 166507 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:27:20: EPOCH 1 - PROGRESS: at 77.76% examples, 166236 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:27:30: EPOCH 1 - PROGRESS: at 80.73% examples, 166109 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:27:40: EPOCH 1 - PROGRESS: at 83.55% examples, 165083 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:27:50: EPOCH 1 - PROGRESS: at 86.36% examples, 163414 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:28:00: EPOCH 1 - PROGRESS: at 88.18% examples, 160359 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:28:10: EPOCH 1 - PROGRESS: at 89.48% examples, 156592 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:28:20: EPOCH 1 - PROGRESS: at 91.85% examples, 154511 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:28:30: EPOCH 1 - PROGRESS: at 94.88% examples, 153670 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:28:40: EPOCH 1 - PROGRESS: at 97.42% examples, 152107 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:28:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:28:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:28:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:28:48: EPOCH - 1 : training on 51151273 raw words (43948358 effective words) took 290.2s, 151425 effective words/s\n",
      "INFO - 00:28:49: EPOCH 2 - PROGRESS: at 0.26% examples, 102054 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:29:00: EPOCH 2 - PROGRESS: at 2.68% examples, 113286 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:29:10: EPOCH 2 - PROGRESS: at 6.18% examples, 136906 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:29:20: EPOCH 2 - PROGRESS: at 10.09% examples, 147898 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:29:30: EPOCH 2 - PROGRESS: at 14.00% examples, 153269 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:29:40: EPOCH 2 - PROGRESS: at 17.91% examples, 156788 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:29:50: EPOCH 2 - PROGRESS: at 21.55% examples, 157299 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:30:00: EPOCH 2 - PROGRESS: at 25.34% examples, 158629 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:30:10: EPOCH 2 - PROGRESS: at 29.14% examples, 159774 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:30:20: EPOCH 2 - PROGRESS: at 33.05% examples, 161089 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:30:30: EPOCH 2 - PROGRESS: at 36.75% examples, 161190 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:30:40: EPOCH 2 - PROGRESS: at 40.65% examples, 162066 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:30:50: EPOCH 2 - PROGRESS: at 44.37% examples, 162077 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:31:00: EPOCH 2 - PROGRESS: at 48.25% examples, 162669 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:31:10: EPOCH 2 - PROGRESS: at 52.43% examples, 163365 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:31:20: EPOCH 2 - PROGRESS: at 57.01% examples, 164155 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:31:30: EPOCH 2 - PROGRESS: at 61.55% examples, 164758 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:31:40: EPOCH 2 - PROGRESS: at 66.14% examples, 165391 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:31:50: EPOCH 2 - PROGRESS: at 70.54% examples, 165530 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:32:00: EPOCH 2 - PROGRESS: at 73.56% examples, 162911 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:32:10: EPOCH 2 - PROGRESS: at 75.91% examples, 161110 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:32:21: EPOCH 2 - PROGRESS: at 78.24% examples, 159411 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:32:31: EPOCH 2 - PROGRESS: at 80.31% examples, 157360 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:32:41: EPOCH 2 - PROGRESS: at 83.51% examples, 157705 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:32:51: EPOCH 2 - PROGRESS: at 87.17% examples, 158099 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:33:01: EPOCH 2 - PROGRESS: at 89.64% examples, 156696 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:33:11: EPOCH 2 - PROGRESS: at 93.01% examples, 156323 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:33:21: EPOCH 2 - PROGRESS: at 95.89% examples, 155166 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:33:31: EPOCH 2 - PROGRESS: at 98.89% examples, 154151 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:33:34: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:33:34: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:33:34: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:33:34: EPOCH - 2 : training on 51151273 raw words (43949005 effective words) took 285.6s, 153903 effective words/s\n",
      "INFO - 00:33:35: EPOCH 3 - PROGRESS: at 0.32% examples, 126247 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:33:45: EPOCH 3 - PROGRESS: at 2.88% examples, 123038 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:33:55: EPOCH 3 - PROGRESS: at 5.95% examples, 132937 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:34:05: EPOCH 3 - PROGRESS: at 9.86% examples, 145168 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:34:15: EPOCH 3 - PROGRESS: at 13.82% examples, 151862 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:34:25: EPOCH 3 - PROGRESS: at 17.75% examples, 155880 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:34:35: EPOCH 3 - PROGRESS: at 21.66% examples, 158610 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:34:45: EPOCH 3 - PROGRESS: at 25.58% examples, 160471 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:34:55: EPOCH 3 - PROGRESS: at 28.70% examples, 157785 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:35:05: EPOCH 3 - PROGRESS: at 32.62% examples, 159288 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:35:15: EPOCH 3 - PROGRESS: at 36.56% examples, 160517 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:35:25: EPOCH 3 - PROGRESS: at 40.51% examples, 161651 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:35:35: EPOCH 3 - PROGRESS: at 44.45% examples, 162472 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:35:45: EPOCH 3 - PROGRESS: at 48.35% examples, 163147 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:35:56: EPOCH 3 - PROGRESS: at 51.98% examples, 162251 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:36:06: EPOCH 3 - PROGRESS: at 55.87% examples, 161358 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:36:16: EPOCH 3 - PROGRESS: at 60.50% examples, 162321 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:36:26: EPOCH 3 - PROGRESS: at 65.12% examples, 163172 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:36:36: EPOCH 3 - PROGRESS: at 69.73% examples, 163947 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:36:46: EPOCH 3 - PROGRESS: at 74.14% examples, 164497 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:36:56: EPOCH 3 - PROGRESS: at 77.09% examples, 164491 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:37:06: EPOCH 3 - PROGRESS: at 80.09% examples, 164465 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:37:16: EPOCH 3 - PROGRESS: at 83.21% examples, 164543 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:37:26: EPOCH 3 - PROGRESS: at 86.98% examples, 164755 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:37:36: EPOCH 3 - PROGRESS: at 90.28% examples, 164507 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:37:46: EPOCH 3 - PROGRESS: at 94.17% examples, 164680 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:37:56: EPOCH 3 - PROGRESS: at 97.60% examples, 164068 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:38:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:38:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:38:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:38:03: EPOCH - 3 : training on 51151273 raw words (43950060 effective words) took 268.6s, 163598 effective words/s\n",
      "INFO - 00:38:04: EPOCH 4 - PROGRESS: at 0.37% examples, 155305 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:38:14: EPOCH 4 - PROGRESS: at 3.76% examples, 160066 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:38:24: EPOCH 4 - PROGRESS: at 7.39% examples, 162446 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:38:34: EPOCH 4 - PROGRESS: at 11.30% examples, 165381 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:38:44: EPOCH 4 - PROGRESS: at 15.20% examples, 166660 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:38:54: EPOCH 4 - PROGRESS: at 19.02% examples, 166904 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:39:04: EPOCH 4 - PROGRESS: at 22.89% examples, 167479 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:39:14: EPOCH 4 - PROGRESS: at 26.80% examples, 168205 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:39:24: EPOCH 4 - PROGRESS: at 30.63% examples, 168336 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:39:34: EPOCH 4 - PROGRESS: at 34.56% examples, 168782 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:39:44: EPOCH 4 - PROGRESS: at 38.53% examples, 169132 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:39:54: EPOCH 4 - PROGRESS: at 42.34% examples, 168950 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:40:04: EPOCH 4 - PROGRESS: at 46.24% examples, 169030 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:40:14: EPOCH 4 - PROGRESS: at 50.15% examples, 169241 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:40:24: EPOCH 4 - PROGRESS: at 54.58% examples, 169308 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:40:34: EPOCH 4 - PROGRESS: at 59.15% examples, 169716 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:40:44: EPOCH 4 - PROGRESS: at 63.75% examples, 170088 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:40:54: EPOCH 4 - PROGRESS: at 68.21% examples, 170160 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:41:04: EPOCH 4 - PROGRESS: at 72.80% examples, 170475 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:41:14: EPOCH 4 - PROGRESS: at 76.11% examples, 170233 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:41:24: EPOCH 4 - PROGRESS: at 79.09% examples, 169911 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:41:34: EPOCH 4 - PROGRESS: at 82.01% examples, 169561 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:41:44: EPOCH 4 - PROGRESS: at 85.78% examples, 169571 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:41:55: EPOCH 4 - PROGRESS: at 89.08% examples, 169421 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:42:05: EPOCH 4 - PROGRESS: at 93.03% examples, 169457 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:42:15: EPOCH 4 - PROGRESS: at 96.97% examples, 169504 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:42:22: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:42:22: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:42:22: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:42:22: EPOCH - 4 : training on 51151273 raw words (43949320 effective words) took 259.2s, 169536 effective words/s\n",
      "INFO - 00:42:23: EPOCH 5 - PROGRESS: at 0.37% examples, 153688 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:42:33: EPOCH 5 - PROGRESS: at 3.79% examples, 162557 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:42:43: EPOCH 5 - PROGRESS: at 7.52% examples, 165039 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:42:53: EPOCH 5 - PROGRESS: at 11.08% examples, 162118 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:43:03: EPOCH 5 - PROGRESS: at 15.03% examples, 164644 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:43:13: EPOCH 5 - PROGRESS: at 18.95% examples, 166052 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:43:23: EPOCH 5 - PROGRESS: at 22.86% examples, 167087 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:43:33: EPOCH 5 - PROGRESS: at 26.72% examples, 167626 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:43:43: EPOCH 5 - PROGRESS: at 30.30% examples, 166334 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:43:53: EPOCH 5 - PROGRESS: at 34.21% examples, 166922 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:44:03: EPOCH 5 - PROGRESS: at 38.37% examples, 168368 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:44:13: EPOCH 5 - PROGRESS: at 42.50% examples, 169437 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:44:23: EPOCH 5 - PROGRESS: at 46.60% examples, 170024 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:44:33: EPOCH 5 - PROGRESS: at 50.75% examples, 170931 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:44:44: EPOCH 5 - PROGRESS: at 55.58% examples, 171801 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:44:54: EPOCH 5 - PROGRESS: at 60.12% examples, 171904 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:45:04: EPOCH 5 - PROGRESS: at 64.97% examples, 172687 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:45:14: EPOCH 5 - PROGRESS: at 69.58% examples, 172906 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:45:24: EPOCH 5 - PROGRESS: at 73.94% examples, 172665 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:45:34: EPOCH 5 - PROGRESS: at 77.05% examples, 172692 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:45:44: EPOCH 5 - PROGRESS: at 80.19% examples, 172695 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:45:54: EPOCH 5 - PROGRESS: at 83.45% examples, 172559 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:46:04: EPOCH 5 - PROGRESS: at 87.41% examples, 172907 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:46:14: EPOCH 5 - PROGRESS: at 91.18% examples, 173133 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:46:24: EPOCH 5 - PROGRESS: at 95.31% examples, 173376 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:46:34: EPOCH 5 - PROGRESS: at 99.67% examples, 173719 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:46:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:46:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:46:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:46:35: EPOCH - 5 : training on 51151273 raw words (43948617 effective words) took 252.9s, 173777 effective words/s\n",
      "INFO - 00:46:36: EPOCH 6 - PROGRESS: at 0.37% examples, 160625 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:46:46: EPOCH 6 - PROGRESS: at 3.95% examples, 170558 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:46:56: EPOCH 6 - PROGRESS: at 7.86% examples, 173738 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:47:06: EPOCH 6 - PROGRESS: at 11.96% examples, 175524 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:47:16: EPOCH 6 - PROGRESS: at 16.11% examples, 176877 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:47:26: EPOCH 6 - PROGRESS: at 20.14% examples, 177039 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:47:36: EPOCH 6 - PROGRESS: at 24.26% examples, 177725 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:47:46: EPOCH 6 - PROGRESS: at 28.30% examples, 177792 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:47:56: EPOCH 6 - PROGRESS: at 32.43% examples, 178214 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:48:06: EPOCH 6 - PROGRESS: at 36.42% examples, 177755 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:48:16: EPOCH 6 - PROGRESS: at 40.55% examples, 178113 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:48:26: EPOCH 6 - PROGRESS: at 44.66% examples, 178221 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:48:36: EPOCH 6 - PROGRESS: at 48.80% examples, 178416 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:48:46: EPOCH 6 - PROGRESS: at 53.32% examples, 178819 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:48:56: EPOCH 6 - PROGRESS: at 58.16% examples, 179231 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:49:06: EPOCH 6 - PROGRESS: at 63.01% examples, 179622 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:49:16: EPOCH 6 - PROGRESS: at 67.87% examples, 179956 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:49:26: EPOCH 6 - PROGRESS: at 72.65% examples, 180115 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:49:36: EPOCH 6 - PROGRESS: at 76.16% examples, 179776 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:49:47: EPOCH 6 - PROGRESS: at 79.32% examples, 179410 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:49:57: EPOCH 6 - PROGRESS: at 82.42% examples, 179069 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:50:07: EPOCH 6 - PROGRESS: at 86.31% examples, 178760 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:50:17: EPOCH 6 - PROGRESS: at 89.91% examples, 178672 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:50:27: EPOCH 6 - PROGRESS: at 94.03% examples, 178678 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:50:37: EPOCH 6 - PROGRESS: at 98.21% examples, 178720 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:50:40: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:50:40: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:50:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:50:41: EPOCH - 6 : training on 51151273 raw words (43947797 effective words) took 245.8s, 178826 effective words/s\n",
      "INFO - 00:50:42: EPOCH 7 - PROGRESS: at 0.39% examples, 170788 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:50:52: EPOCH 7 - PROGRESS: at 3.49% examples, 150436 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:51:02: EPOCH 7 - PROGRESS: at 7.11% examples, 157716 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:51:12: EPOCH 7 - PROGRESS: at 11.22% examples, 165000 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:51:22: EPOCH 7 - PROGRESS: at 15.34% examples, 168553 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:51:32: EPOCH 7 - PROGRESS: at 19.35% examples, 170064 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:51:42: EPOCH 7 - PROGRESS: at 23.44% examples, 171659 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:51:52: EPOCH 7 - PROGRESS: at 27.54% examples, 172899 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:52:02: EPOCH 7 - PROGRESS: at 31.60% examples, 173594 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:52:12: EPOCH 7 - PROGRESS: at 35.71% examples, 174320 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:52:22: EPOCH 7 - PROGRESS: at 39.82% examples, 174756 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:52:32: EPOCH 7 - PROGRESS: at 43.97% examples, 175320 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:52:42: EPOCH 7 - PROGRESS: at 48.10% examples, 175714 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:52:52: EPOCH 7 - PROGRESS: at 52.41% examples, 175929 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:53:02: EPOCH 7 - PROGRESS: at 57.23% examples, 176562 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:53:12: EPOCH 7 - PROGRESS: at 62.08% examples, 177117 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:53:22: EPOCH 7 - PROGRESS: at 66.83% examples, 177444 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:53:32: EPOCH 7 - PROGRESS: at 71.68% examples, 177887 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:53:42: EPOCH 7 - PROGRESS: at 75.57% examples, 178038 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:53:52: EPOCH 7 - PROGRESS: at 79.26% examples, 179357 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:54:02: EPOCH 7 - PROGRESS: at 83.10% examples, 180774 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:54:12: EPOCH 7 - PROGRESS: at 87.85% examples, 182459 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:54:22: EPOCH 7 - PROGRESS: at 92.49% examples, 183879 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:54:32: EPOCH 7 - PROGRESS: at 97.48% examples, 185279 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:54:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:54:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:54:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:54:37: EPOCH - 7 : training on 51151273 raw words (43947157 effective words) took 236.3s, 185986 effective words/s\n",
      "INFO - 00:54:38: EPOCH 8 - PROGRESS: at 0.48% examples, 204889 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:54:48: EPOCH 8 - PROGRESS: at 4.78% examples, 205743 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:54:58: EPOCH 8 - PROGRESS: at 9.78% examples, 213093 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:55:08: EPOCH 8 - PROGRESS: at 14.84% examples, 215599 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:55:18: EPOCH 8 - PROGRESS: at 19.08% examples, 208523 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:55:28: EPOCH 8 - PROGRESS: at 22.82% examples, 199953 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:55:38: EPOCH 8 - PROGRESS: at 27.74% examples, 202778 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:55:48: EPOCH 8 - PROGRESS: at 32.37% examples, 202867 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:55:58: EPOCH 8 - PROGRESS: at 36.30% examples, 199138 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:56:08: EPOCH 8 - PROGRESS: at 40.43% examples, 197035 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:56:18: EPOCH 8 - PROGRESS: at 44.60% examples, 195492 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:56:28: EPOCH 8 - PROGRESS: at 48.72% examples, 194123 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:56:38: EPOCH 8 - PROGRESS: at 53.23% examples, 193285 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:56:48: EPOCH 8 - PROGRESS: at 58.12% examples, 192798 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:56:58: EPOCH 8 - PROGRESS: at 62.99% examples, 192371 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:57:08: EPOCH 8 - PROGRESS: at 67.85% examples, 191922 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:57:18: EPOCH 8 - PROGRESS: at 72.74% examples, 191591 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:57:28: EPOCH 8 - PROGRESS: at 76.20% examples, 190611 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:57:38: EPOCH 8 - PROGRESS: at 79.38% examples, 189689 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:57:48: EPOCH 8 - PROGRESS: at 82.48% examples, 188801 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:57:59: EPOCH 8 - PROGRESS: at 86.52% examples, 188314 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:58:09: EPOCH 8 - PROGRESS: at 90.16% examples, 187794 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:58:19: EPOCH 8 - PROGRESS: at 94.35% examples, 187511 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:58:29: EPOCH 8 - PROGRESS: at 98.54% examples, 187185 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:58:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:58:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:58:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:58:32: EPOCH - 8 : training on 51151273 raw words (43950285 effective words) took 234.8s, 187155 effective words/s\n",
      "INFO - 00:58:33: EPOCH 9 - PROGRESS: at 0.39% examples, 163433 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:58:43: EPOCH 9 - PROGRESS: at 3.97% examples, 170257 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:58:53: EPOCH 9 - PROGRESS: at 7.89% examples, 173535 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:59:03: EPOCH 9 - PROGRESS: at 12.00% examples, 175376 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:59:13: EPOCH 9 - PROGRESS: at 16.13% examples, 176544 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:59:23: EPOCH 9 - PROGRESS: at 20.14% examples, 176571 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:59:33: EPOCH 9 - PROGRESS: at 24.23% examples, 177204 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 00:59:43: EPOCH 9 - PROGRESS: at 28.28% examples, 177438 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 00:59:53: EPOCH 9 - PROGRESS: at 32.05% examples, 175915 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 01:00:03: EPOCH 9 - PROGRESS: at 35.94% examples, 175288 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:00:13: EPOCH 9 - PROGRESS: at 40.06% examples, 175749 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:00:23: EPOCH 9 - PROGRESS: at 44.13% examples, 175924 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:00:33: EPOCH 9 - PROGRESS: at 48.23% examples, 176287 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 01:00:43: EPOCH 9 - PROGRESS: at 52.65% examples, 176761 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 01:00:53: EPOCH 9 - PROGRESS: at 56.99% examples, 175918 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:01:03: EPOCH 9 - PROGRESS: at 61.73% examples, 176255 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:01:13: EPOCH 9 - PROGRESS: at 66.54% examples, 176785 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:01:23: EPOCH 9 - PROGRESS: at 71.30% examples, 177096 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 01:01:33: EPOCH 9 - PROGRESS: at 75.29% examples, 177185 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:01:43: EPOCH 9 - PROGRESS: at 78.39% examples, 176926 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:01:53: EPOCH 9 - PROGRESS: at 81.19% examples, 175790 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:02:03: EPOCH 9 - PROGRESS: at 84.72% examples, 175297 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 01:02:13: EPOCH 9 - PROGRESS: at 88.28% examples, 175241 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 01:02:24: EPOCH 9 - PROGRESS: at 92.16% examples, 175232 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:02:34: EPOCH 9 - PROGRESS: at 96.31% examples, 175393 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 01:02:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 01:02:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 01:02:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 01:02:42: EPOCH - 9 : training on 51151273 raw words (43950446 effective words) took 250.3s, 175597 effective words/s\n",
      "INFO - 01:02:43: EPOCH 10 - PROGRESS: at 0.39% examples, 165441 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:02:53: EPOCH 10 - PROGRESS: at 3.79% examples, 163208 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:03:03: EPOCH 10 - PROGRESS: at 6.95% examples, 153613 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:03:13: EPOCH 10 - PROGRESS: at 11.02% examples, 161572 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:03:23: EPOCH 10 - PROGRESS: at 15.16% examples, 166343 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:03:33: EPOCH 10 - PROGRESS: at 19.29% examples, 169336 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:03:43: EPOCH 10 - PROGRESS: at 23.15% examples, 169174 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:03:53: EPOCH 10 - PROGRESS: at 26.43% examples, 165753 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:04:03: EPOCH 10 - PROGRESS: at 29.65% examples, 162878 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 01:04:13: EPOCH 10 - PROGRESS: at 32.82% examples, 160245 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 01:04:23: EPOCH 10 - PROGRESS: at 35.88% examples, 157696 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:04:33: EPOCH 10 - PROGRESS: at 39.41% examples, 157409 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:04:43: EPOCH 10 - PROGRESS: at 43.40% examples, 158734 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:04:53: EPOCH 10 - PROGRESS: at 47.55% examples, 160438 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 01:05:04: EPOCH 10 - PROGRESS: at 51.69% examples, 161493 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 01:05:14: EPOCH 10 - PROGRESS: at 56.33% examples, 162594 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:05:24: EPOCH 10 - PROGRESS: at 60.90% examples, 163338 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:05:34: EPOCH 10 - PROGRESS: at 65.59% examples, 164277 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:05:44: EPOCH 10 - PROGRESS: at 69.34% examples, 162800 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:05:54: EPOCH 10 - PROGRESS: at 72.32% examples, 160288 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:06:04: EPOCH 10 - PROGRESS: at 75.54% examples, 159971 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:06:14: EPOCH 10 - PROGRESS: at 78.66% examples, 160547 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 01:06:24: EPOCH 10 - PROGRESS: at 81.74% examples, 161065 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 01:06:34: EPOCH 10 - PROGRESS: at 85.63% examples, 161808 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:06:44: EPOCH 10 - PROGRESS: at 89.12% examples, 162372 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 01:06:54: EPOCH 10 - PROGRESS: at 93.25% examples, 163040 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:07:04: EPOCH 10 - PROGRESS: at 97.42% examples, 163688 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 01:07:10: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 01:07:10: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 01:07:10: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 01:07:10: EPOCH - 10 : training on 51151273 raw words (43946815 effective words) took 267.8s, 164109 effective words/s\n",
      "INFO - 01:07:10: training on a 511512730 raw words (439487860 effective words) took 2591.6s, 169578 effective words/s\n",
      "INFO - 01:07:14: storing 72827x100 projection weights into embeddings.txt\n"
     ]
    }
   ],
   "source": [
    "fasttext_model = train_fasttext(tokenized_text=tokens, size=100, window=5, min_count=20, epochs=10, random_seed=123,\n",
    "                                vec_file_path=os.path.join('embeddings.txt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# fasttext model's vocab size\n",
    "print(f'fasttext model\\'s vocabulary size: {len(fasttext_model.wv.vocab):,}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext model's vocabulary size: 72,827\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate embeddings\n",
    "Here we evaluate the embeddings learned by just 👀 at the neighbours of a few words and examining if they are similar.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 01:07:19: precomputing L2-norms of word weight vectors\n",
      "INFO - 01:07:19: precomputing L2-norms of ngram weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('ଗଛଡାଳ', 0.8624626994132996),\n ('ବରଗଛ', 0.8271986842155457),\n ('ଗଛର', 0.8181042075157166),\n ('ଗଛଟି', 0.7930528521537781),\n ('ଆମ୍ବଗଛ', 0.7569365501403809),\n ('ଗଛକାଟି', 0.7496357560157776),\n ('ଫୁଲଗଛ', 0.7436925172805786),\n ('କଦଳୀଗଛ', 0.7428790926933289),\n ('ଗଛଟିଏ', 0.735636293888092),\n ('ଶାଳଗଛ', 0.7351911067962646)]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## find words similar to a given word\n",
    "fasttext_model.wv.most_similar('ଗଛ', topn=10)  # TODO: misspell it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[('ସଂଗୀତ', 0.9560882449150085),\n ('ସଂଙ୍ଗୀତ', 0.9518374800682068),\n ('ସଙ୍ଗୀତର', 0.9251900315284729),\n ('ସଙ୍ଗୀତକାର', 0.8922179341316223),\n ('ସଂଗୀତର', 0.887881338596344),\n ('ସଂଗୀତକାର', 0.880925714969635),\n ('ସଙ୍ଗୀତଜ୍ଞ', 0.8672783374786377),\n ('ଗୀତିନାଟ୍ୟ', 0.8656123876571655),\n ('ନୃତ୍ୟଗୀତ', 0.8506015539169312),\n ('ନାଟ୍ୟ', 0.8301488757133484)]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('ସଙ୍ଗୀତ', topn=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[('ଚଳଚିତ୍ର', 0.9286938905715942),\n ('ଚଳଚ୍ଚିତ୍ରଟି', 0.9178325533866882),\n ('ଚଳଚ୍ଚିତ୍ରଟିର', 0.9093020558357239),\n ('ଚଳଚ୍ଚିତ୍ରର', 0.8912208080291748),\n ('ସିନେମାଟୋଗ୍ରାଫର', 0.8442597389221191),\n ('ସିନେମା', 0.835664689540863),\n ('ଚଳଚ୍ଚିତ୍ରରେ', 0.8248735666275024),\n ('ଫିଲ୍ମ', 0.8236875534057617),\n ('ସିନେ', 0.8232754468917847),\n ('ଚଳଚ୍ଚିତ୍ରଟିରେ', 0.8230992555618286)]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('ଚଳଚ୍ଚିତ୍ର', topn=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Try some misspelled words**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[('ଚଳଚ୍ଚିତ୍ର', 0.8185211420059204),\n ('ଚଳଚ୍ଚିତ୍ରଟିର', 0.7849276065826416),\n ('ଚଳଚ୍ଚିତ୍ରଟି', 0.7687302231788635),\n ('ଚଳଚ୍ଚିତ୍ରର', 0.7509340047836304),\n ('ସମୁଚ୍ଚିତ', 0.7431687116622925),\n ('ସିନେମାଟୋଗ୍ରାଫର', 0.7184866666793823),\n ('ଲୋକପ୍ରିୟ', 0.717289388179779),\n ('ସିନେ', 0.7128420472145081),\n ('ଚଳଚ୍ଚିତ୍ରଟିରେ', 0.7066846489906311),\n ('ଫିଲ୍ମ', 0.7031621336936951)]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('ଚଳଚ୍ଚିତ', topn=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "[('ଗୀତ', 0.9340874552726746),\n ('ନାଚଗୀତ', 0.892783522605896),\n ('ସଂଙ୍ଗୀତ', 0.8845723867416382),\n ('ନୃତ୍ୟଗୀତ', 0.8834997415542603),\n ('ସଂଗୀତ', 0.8760308027267456),\n ('ସଙ୍ଗୀତ', 0.87196946144104),\n ('ଗୀତ୍', 0.8635718822479248),\n ('ଗୀତିନାଟ୍ୟ', 0.8207296133041382),\n ('ଗୀତର', 0.8093352317810059),\n ('ନାଚଗୀତର', 0.806583821773529)]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('ସଗୀତ', topn=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}